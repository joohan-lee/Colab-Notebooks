{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word_pred_tf.ipynb","provenance":[],"authorship_tag":"ABX9TyPgFTQx/tmLbbNFdzRS3D5x"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dwuBL7Lcdl7n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":981},"outputId":"72745a04-5a5d-49e9-92d2-72038ac5c971","executionInfo":{"status":"ok","timestamp":1584380951079,"user_tz":-540,"elapsed":4148,"user":{"displayName":"이주한","photoUrl":"","userId":"11677144677478737443"}}},"source":["#-*- coding: utf-8 -*-\n","#word에서 wor과 d를 떼어내서 d를 맞추도록 함. 주가데이터에서 7일까지기준, 1~3일데이터로 4일데이터를 맞추고 2~4로 5일을 맞추도록 훈련시킨 후 5~7로 8일을 예측해보는 느낌.\n","\n","\n","import sys\n","import tensorflow as tf\n","import numpy as np\n"," \n","char_arr = [chr(ch) for ch in range(97, 123)]\n"," \n","num_dic = {n: i for i, n in enumerate(char_arr)}\n","dic_len = len(num_dic)\n"," \n","seq_data = ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load',\n","    'love', 'kiss', 'kind']\n"," \n","\n","def make_batch(seq_data):\n","    input_batch = []\n","    target_batch = []\n"," \n","    for seq in seq_data:\n","        input = [num_dic[n] for n in seq[:-1]]\n","        target = num_dic[seq[-1]]\n","        input_batch.append(np.eye(dic_len)[input])\n","        target_batch.append(target)\n"," \n","    return input_batch, target_batch\n"," \n","learning_rate = 0.01\n","n_hidden = 128\n","total_epoch = 30\n"," \n","n_step = 3\n","n_input = n_class = dic_len\n"," \n","X = tf.placeholder(tf.float32, [None, n_step, n_input])\n","Y = tf.placeholder(tf.int32, [None])\n"," \n","W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n","b = tf.Variable(tf.random_normal([n_class]))\n"," \n","cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n","cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n","cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n"," \n","multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n"," \n","outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n"," \n","outputs = tf.transpose(outputs, [1, 0, 2])\n","outputs = outputs[-1]\n","model = tf.matmul(outputs, W) + b\n"," \n","cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n","    logits=model, labels=Y\n","))\n"," \n","optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n"," \n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n"," \n","    input_batch, target_batch = make_batch(seq_data)\n"," \n","    for epoch in range(total_epoch):\n","        _, loss = sess.run([optimizer, cost],\n","            feed_dict={X: input_batch, Y: target_batch})\n"," \n","        print('Epoch:', '%04d' % (epoch + 1),\n","            'cost =', '{:.6f}'.format(loss))\n","        sys.stdout.flush()\n"," \n","    print('완료!')\n"," \n","    prediction = tf.cast(tf.argmax(model, 1), tf.int32)\n","    prediction_check = tf.equal(prediction, Y)\n","    accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n"," \n","    input_batch, target_batch = make_batch(seq_data)\n"," \n","    predict, accuracy_val = sess.run([prediction, accuracy],\n","        feed_dict={X: input_batch, Y: target_batch})\n"," \n","    predict_words = []\n","    for idx, val in enumerate(seq_data):\n","        last_char = char_arr[predict[idx]]\n","        predict_words.append(val[:3] + last_char)\n"," \n","    print('\\n=== 예측 결과 ===')\n","    print('입력값:', [w[:3] + ' ' for w in seq_data])\n","    print('예측값:', predict_words)\n","    print('정확도:', accuracy_val)\n"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-1-3d9ed542ad0a>:41: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-1-3d9ed542ad0a>:45: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-1-3d9ed542ad0a>:47: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","Epoch: 0001 cost = 3.665632\n","Epoch: 0002 cost = 2.710828\n","Epoch: 0003 cost = 1.770254\n","Epoch: 0004 cost = 1.159874\n","Epoch: 0005 cost = 1.163783\n","Epoch: 0006 cost = 0.818523\n","Epoch: 0007 cost = 0.555326\n","Epoch: 0008 cost = 0.541563\n","Epoch: 0009 cost = 0.350958\n","Epoch: 0010 cost = 0.228672\n","Epoch: 0011 cost = 0.285247\n","Epoch: 0012 cost = 0.487143\n","Epoch: 0013 cost = 0.276192\n","Epoch: 0014 cost = 0.098794\n","Epoch: 0015 cost = 0.148612\n","Epoch: 0016 cost = 0.149326\n","Epoch: 0017 cost = 0.137269\n","Epoch: 0018 cost = 0.069043\n","Epoch: 0019 cost = 0.038340\n","Epoch: 0020 cost = 0.079158\n","Epoch: 0021 cost = 0.046935\n","Epoch: 0022 cost = 0.071325\n","Epoch: 0023 cost = 0.044495\n","Epoch: 0024 cost = 0.046673\n","Epoch: 0025 cost = 0.137354\n","Epoch: 0026 cost = 0.021037\n","Epoch: 0027 cost = 0.056513\n","Epoch: 0028 cost = 0.091807\n","Epoch: 0029 cost = 0.039419\n","Epoch: 0030 cost = 0.010347\n","완료!\n","\n","=== 예측 결과 ===\n","입력값: ['wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n","예측값: ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n","정확도: 1.0\n"],"name":"stdout"}]}]}